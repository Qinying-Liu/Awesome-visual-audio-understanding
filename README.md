# awesome-visual-audio-understanding
Collection of papers about video-audio understanding

1. <span id = "1001">**[VITA]**</span> | **Arxiv'2408** | VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs | [`[pdf]`](https://arxiv.org/abs/2406.07476) | [`[code]`](https://github.com/DAMO-NLP-SG/VideoLLaMA2)
2. <span id = "1001">**[VITA]**</span> | **Arxiv'2408** | VITA: Towards Open-Source Interactive Omni Multimodal LLM | [`[pdf]`](https://arxiv.org/pdf/2408.05211) | [`[code]`](https://vita-home.github.io)
3. <span id = "1002">**[VITA 1.5]**</span> | **Arxiv'2501** | VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction | [`[pdf]`](https://arxiv.org/pdf/2501.01957) | [`[code]`](https://vita-home.github.io)
4. <span id = "1003">**[Ola]**</span> | **Arxiv'2502** | Ola: Pushing the Frontiers of Omni-Modal Language Model | [`[pdf]`](https://arxiv.org/pdf/2502.04328) | [`[code]`](https://ola-omni.github.io)
5. <span id = "1005">**[EchoInk-R1]**</span> | **Arxiv'2505** | EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning | [`[pdf]`](https://arxiv.org/pdf/2505.04623) | [`[code]`](https://github.com/HarryHsing/EchoInk)
6. <span id = "1004">**[HumanOmniV2]**</span> | **Arxiv'2506** | HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context | [`[pdf]`](https://arxiv.org/pdf/2506.21277) | [`[code]`](https://github.com/HumanMLLM/HumanOmniV2)
